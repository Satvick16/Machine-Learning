{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine-learning-crash-course.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLhsvg9yXdFn9tLdGM4kN3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satvick16/Machine-Learning/blob/master/machine_learning_crash_course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ37Shft_xuU",
        "colab_type": "text"
      },
      "source": [
        "# Google Colab Machine Learning Crash Course (MLCC)\n",
        "\n",
        "Markdown Guide: https://colab.research.google.com/notebooks/markdown_guide.ipynb\n",
        "\n",
        "Terminology:\n",
        "\n",
        "    labels (y): variable to be predicted\n",
        "    features (x1, x2,...xn): input variables describing data (quantifiable)\n",
        "\n",
        "    examples\n",
        "        labelled example: x and y are known >>> trains model (data set)\n",
        "        unlabelled example: x is known >>> making predictions on new data\n",
        "\n",
        "    model (y'): defined by internal prameters which it learns\n",
        "        regression model: predicts continuous values\n",
        "        classification model: predicts discrete values\n",
        "    \n",
        "    inferencing: applying model to unlabelled examples\n",
        "\n",
        "Regression:\n",
        "\n",
        "    y' = b + w1x1\n",
        "        y': prediction\n",
        "        w1: weight for feature 1\n",
        "        x1: feature 1\n",
        "        b: bias\n",
        "\n",
        "$L2 loss = \\sum_{(x, y) ε D}^\\ \\ (y - y')^2$\n",
        "\n",
        "$Mean Squared Error = \\frac{1}{N}\\sum_{(x, y) ε D}^\\ \\ (y - y')^2$\n",
        "\n",
        "    D: data set\n",
        "    N: number of examples in D\n",
        "\n",
        "Gradient Descent (iterative way to train model):\n",
        "\n",
        "    Take derivative of (y - y')^2 w.r.t. weights and biases.\n",
        "    Negative derivative determines direction to update the model.\n",
        "\n",
        "    Finding local minimum of loss function.\n",
        "\n",
        "    Learning rate/alpha can be adjusted (step size after taking gradient).\n",
        "    If learning rate is too large, minimum will never be achieved.\n",
        "\n",
        "    Ideal (Goldilocks) learning rate requires minimum iterations.\n",
        "\n",
        "Stochastic Gradient Descent:\n",
        "\n",
        "    batch: number of examples used to calculate gradient in a single interation\n",
        "\n",
        "    Batch size cannot be too large (redundancy + computation power).\n",
        "\n",
        "    SGD uses a batch size of one.\n",
        "\n",
        "TensorFlow Toolkits:\n",
        "\n",
        ">![Google's logo](https://developers.google.com/machine-learning/crash-course/images/TFHierarchyNew.svg)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIEQY-asY9TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Numpy:\n",
        "https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/numpy_ultraquick_tutorial.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=numpy_tf2-colab&hl=en\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 1D and 2D arrays\n",
        "a = np.array([1.2, 2.4, 3.5, 4.7, 6.1, 7.2, 8.3, 9.5])\n",
        "b = np.array([[6, 5], [11, 7], [4, 8]])\n",
        "\n",
        "# populate with zeros or ones\n",
        "c = np.zeros(10)\n",
        "d = np.ones(10)\n",
        "\n",
        "# sequential array\n",
        "ordered_array = np.arange(5, 12)\n",
        "\n",
        "# random arrays\n",
        "random_ints = np.random.randint(low=50, high=101, size=6)\n",
        "random_floats = np.random.random([6])\n",
        "\n",
        "# operations on arrays\n",
        "random_floats_plus_2 = random_floats + 2.0\n",
        "random_ints_times_3 = random_ints * 3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mERa-X1BZvdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Pandas:\n",
        "https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=pandas_tf2-colab&hl=en\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = np.array([[0, 3], [10, 7], [20, 9], [30, 14], [40, 15]])\n",
        "column_names = ['temperature', 'activity']\n",
        "\n",
        "# pd.DataFrame takes params data and column names\n",
        "dataframe = pd.DataFrame(data=data, columns=column_names)\n",
        "\n",
        "# adding a column\n",
        "dataframe['adjusted'] = dataframe['activity'] + 2\n",
        "\n",
        "# first 3 rows\n",
        "print(dataframe.head(3), '\\n')\n",
        "\n",
        "# second row\n",
        "print(dataframe.iloc[[2]], '\\n')\n",
        "\n",
        "# specific value\n",
        "print(dataframe.iloc[0][1], '\\n')\n",
        "\n",
        "# row slicing\n",
        "print(dataframe[1:4], '\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}